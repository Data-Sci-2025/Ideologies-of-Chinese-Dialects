---
title: "data"
author: "Zihan Gao"
data: "Oct 27, 2025"
format: gfm
---

## Progress report 1
## Zihan Gao
## Oct 28, 2025


### My study
#### Title
Dialects reduce attractiveness?: A Study of Language Attitudes and Stereotypes toward Chinese Dialects on Social Media

#### Background and goal
Some Chinese varieties are considered pleasant-sounding, and people hope to learn them, while others are perceived as “rustic” or “funny.” Therefore, this study aims to explore how different Chinese varieties and accents are perceived on social media.

#### Plan
I plan to analyze videos and comments on Bilibili (https://www.bilibili.com/), a video website featuring danmu — flying comments overlaid on the video.

##### Step 1
My first step is to analyze:
- the number of videos related to each dialect
- the number of views of each video
- the number of likes of each video
- the keywords associated with each dialect or variety (e.g., some dialects are connected with keywords like “funny,” while others are associated with “I wanna learn this dialect”).

##### Step 2
My second step is to extract comments under the top 42 (i.e., first-page) most-reviewed videos for each dialect and rate the positivity of the comments.


### The current progress
Because I did not receive any response from the API request, I started working on extracting data directly from the website. I tried applying the code from Chapter 24 Web Scraping, but it didn’t work for my case, so I asked ChatGPT for help. I tried to ask for specific questions about rvest. ChatGPT provided several possible solutions. Some of them worked, and some didn’t. The following is what worked.

```{r}
# load packages
library(tidyverse)
library(rvest)
library(dplyr)

# name keyword (Cantonese)
keyword <- "粤语"
url <- paste0("https://search.bilibili.com/all?keyword=", URLencode(keyword))

# read the website page
html <- read_html(url)

# read titles
titles <- html |> 
  html_elements(".bili-video-card__info--tit") |>
  html_text2()

titles
```

**I have a lot of questions about the code above. It only produces the correct output when I leave it unchanged; whenever I modify anything, it fails to give the right result.**

#### one step further (did not work)
The code above was able to extract 42 titles with the keyword “Cantonese” from the first page. When I failed to navigate to later pages. Some code returned NULL, and others did not run at all.

```{r}
#| eval: false

# Again, the following code was generated by ChatGPT.
# This one does not work
keyword <- "粤语"
pages <- 1:3  # 比如抓前三页
all_titles <- c()

for (p in pages) {
  url <- paste0("https://search.bilibili.com/all?keyword=", URLencode(keyword), "&page=", p)
  html <- read_html(url)
  titles <- html %>%
    html_elements(".bili-video-card__info--tit") %>%
    html_text2()
  all_titles <- c(all_titles, titles)
}
all_titles
```

#### another step further (did not work)
I also tried to extract view counts and like counts, but I haven’t figured that out yet.

### Next steps
- figure out how to turn pages
- get view counts and like counts
- get comment counts (it seems harder)
- collect data for other dialects
- write the results to a CSV file
- extract keywords (how should I tokenize them as there is no space in Chinese)



**_The following code contains both what I wrote based on the chapter, and what ChatGPT gave me. None of them worked._**

```{r}
# read the HTML into R
# html <- read_html("https://www.bilibili.com/")
```

```{r}
# page_title <- html |> 
#   html_element("title") |> 
#   html_text2()
```


```{r}
# cantonese <- read_html("https://search.bilibili.com/all?keyword=粤语")

# cantonese <- read_html("https://search.bilibili.com/all?keyword=%E7%B2%A4%E8%AF%AD&from_source=webtop_search&spm_id_from=333.1007&search_source=5")
```

```{r}
# titles <- cantonese %>%
#   html_elements(".bili-video-card__info--tit") %>%
#   html_text2()
```


```{r}
# library(httr)
# library(jsonlite)

# keyword <- "粤语"
# url <- paste0(
#   "https://api.bilibili.com/x/web-interface/search/all/v2?",
#   "keyword=", URLencode(keyword),
#   "&pn=1&ps=20"
# )

# res <- GET(url, user_agent("Mozilla/5.0"))  # 模拟浏览器
# json <- fromJSON(content(res, "text", encoding = "UTF-8"))

# str(json, max.level = 3)  # 查看数据结构

```

```{r}
# library(httr)
# url <- "https://api.bilibili.com/x/web-interface/search/all/v2?keyword=粤语&pn=1&ps=20"

# res <- GET(
#   url,
#   user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"),
#   add_headers(
#     Referer = "https://www.bilibili.com/",
#     Accept = "application/json"
#   )
# )

# content(res, "text", encoding = "UTF-8")

```

